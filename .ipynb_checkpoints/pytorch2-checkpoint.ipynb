{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning with python and pytorch.\n",
    "\n",
    "Data - the actual input to a neural network\n",
    "    \n",
    "    acquire data\n",
    "    \n",
    "    preprocess data\n",
    "   \n",
    "   how to iterate over your data\n",
    "\n",
    "This consumes 90% of your time and energy when thinking about your model.\n",
    "    training time can take a long time but requires no work by the programmer\n",
    "    \n",
    "To begin we will use a toy data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\kirks\\anaconda3\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\kirks\\anaconda3\\lib\\site-packages (from torchvision) (1.16.4)\n",
      "Requirement already satisfied: six in c:\\users\\kirks\\anaconda3\\lib\\site-packages (from torchvision) (1.12.0)\n",
      "Requirement already satisfied: torch==1.4.0 in c:\\users\\kirks\\anaconda3\\lib\\site-packages (from torchvision) (1.4.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\kirks\\anaconda3\\lib\\site-packages (from torchvision) (6.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchvision is a bunch of datasets that is used for vision. MNIST is a dataset of 28x28 images of hand-drawn numbers 1-9 and this is what we will be using for this tutorial. It is included free and provided by torchvision.\n",
    "\n",
    "Vision is a good task to benchmark and the main interest that people are working with.\n",
    "    \n",
    "    This is the most business interest and low hanging fruit.\n",
    "    \n",
    "Basically cheating to use their vision data. In order to do neural network deep learning projects, most of your time is going to be spent on getting data, preparing your data and formatting it to work with a neural network.\n",
    "\n",
    "In the future we can introduce original data sets.\n",
    "\n",
    "Lets define two different data sets. tpyically training and testing. They must be seperated in order to validate the model. You have to use data that has never been seen by your model before. You need to do this to avoid over-fitting the training data and it will perform well in production.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\"\", train=True, download=True,\n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST parameters: \n",
    "\n",
    "    first parameter specifies that the data will go locally\n",
    "    Transforms needs to be done because the data is not natively already a tensor.\n",
    "    \n",
    "You can write your own dataset and use this same syntax. It will become obvious how tedious iterating over a data set can be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = datasets.MNIST(\"\",train=False, download=True,\n",
    "                     transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch size is how many data entries are passed to our model at one time. Based on Memory resource allocation ability of the system.\n",
    "\n",
    "Deep learning starts to shine when you have millions and millions of samples in your data. At some point, there will be more samples than you can fit in your memory. This is why you want to control the batch size. The model will be optimized in increments based on those 10 samples at a time in the batch. Everyone likes to use base 8 numbers for their batch size. No real reason for this, but everyone tends to do it. How many neurons per layer is always trial and error. Basically a gradient decent operation.\n",
    "\n",
    "Second reason is that we hope this data will generalize. As the model starts to opimze the weights, if you pass your entire data set at once. The machine might learn some generalization, but the model will also find some weights to be arbitrary. Batches at a time will help each optimization that sticks around in the model with each iteration be confirmed as a generalization and the other optimizations that aren't always there will be classified as over-fitting.\n",
    "\n",
    "There is always a best batch size somewhere between 8 and 64 regardless of how big the memory of the system is. Sometimes you can go bigger batch size and bigger size will impact how quickly you can train through your data.\n",
    "\n",
    "Shuffle parameter lets the data entries be shuffled. The purpose is to do everything we can to help the neural network to learn and optimize for general principals rather than the specifics of the training data. Neural network will always pick the quickest route to report minimal loss. Programmer needs to obfuscate over-fitment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train,batch_size=10,shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test,batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's iterate over this data.\n",
    "\n",
    "Very simpler for us to iterate here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([5, 2, 6, 2, 8, 5, 7, 9, 1, 3])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the entire batch. So it is 10 examples of hand written digits and then 10 tensors of the actual output (the answers).\n",
    "\n",
    "How do we confirm that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "x, y = data[0][0],data[1][0]\n",
    "\n",
    "print(y)\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the shape of the data. 1x28x28. This is not a typical image... Images are 28x28. It is important to note that Pytorch is expecting that dimension for shaping. This can make learning Pytorch very difficult if this is not noted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[0][0].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's talk about iterating over data and then talk about 'balancing'.\n",
    "\n",
    "The model has no idea what is the lowest possible loss. It just tries to decrease loss as best and as easily as possible. Suppose a dataset has skewed frequencies. The model will learn the quickest way to descrease loss such that it will always predict a 3 and the model will be stuck. The model would need to get a lot worse before it can get better again.\n",
    "\n",
    "You can modify the dataset to try to fix imbalanced data, but this rarely works out. It is better to just have balanced dataset from the start.\n",
    "\n",
    "The following code will count how many samples we have for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "counter_dict = {0:0, 1:0, 2:0, 3:0,4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] += 1\n",
    "        total+=1\n",
    "        \n",
    "print(counter_dict)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 9.871666666666666\n",
      "1: 11.236666666666666\n",
      "2: 9.93\n",
      "3: 10.218333333333334\n",
      "4: 9.736666666666666\n",
      "5: 9.035\n",
      "6: 9.863333333333333\n",
      "7: 10.441666666666666\n",
      "8: 9.751666666666667\n",
      "9: 9.915000000000001\n"
     ]
    }
   ],
   "source": [
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the numeral one is slightly more weighted than the others. This dataset is probably balanced enough and will not cause any issues. 11% compared to 9%, the quickest way to a optimization  would be if the model guessed everything was a one. The model would only get 11% whereas random will give it 10%, chances are it will be able to work with this dataset distribution.\n",
    "\n",
    "Data is more important than the neural network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
