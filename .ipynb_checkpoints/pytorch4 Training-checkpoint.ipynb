{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to pass through labeled data and train the model to recognize the data. We want the model to reach a state where it can view datasets it has never seen before and predict and recognize the answer.\n",
    "\n",
    "Introduce 2 new concepts: Loss and optimizer.\n",
    "\n",
    "Loss is how wrong the model is. If a model predicts correctly, chances are the model was wrong in some way. Some degree of error is there.\n",
    "\n",
    "Optimizer has a job to go through and adjust the weights for all the neurons in such a way so as to lower the loss over time. This is the \"learning\" rate that is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "train = datasets.MNIST('', train = True, download=True,\n",
    "                      transform=transforms.Compose([\n",
    "                          transforms.ToTensor()\n",
    "                      ]))\n",
    "\n",
    "test = datasets.MNIST('', train = False, download=True,\n",
    "                      transform=transforms.Compose([\n",
    "                          transforms.ToTensor()\n",
    "                      ]))\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)\n",
    "\n",
    "\n",
    "#code made in pytorch3.ipynb with comments\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))        \n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)         \n",
    "        return F.log_softmax(x,dim=1)\n",
    "        \n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((28,28))\n",
    "X = X.view(-1,28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3667, -2.1965, -2.3892, -2.2655, -2.2423, -2.2727, -2.3022, -2.3623,\n",
       "         -2.2641, -2.3847]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nTransfer learning: suppose you have a model that is trained\\nand you want to add new layers. You might use transfer learning\\nand freeze the trained layers so your model can't adjust those weights.\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)#paramters is everything adjustable in model\n",
    "'''\n",
    "Transfer learning: suppose you have a model that is trained\n",
    "and you want to add new layers. You might use transfer learning\n",
    "and freeze the trained layers so your model can't adjust those weights.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for the model to learn, it will seek out a minimum point for loss. The learning rate determines the size of the step the network will take in order to step toward a minimum.\n",
    "\n",
    "we don't want to overfit every single data set that is trained on. The steps in the learning rate overwrite the changes made from previous sets. What is desired is for the model to find a balance between every set it has trained on.\\\n",
    "\n",
    "Too small of a step will place the model in a local minima and too large of a step might not be able to enter the absolute minima. There is no way to have knowledge on what the perfect step is. The best is to do a decaying learning rate: large steps at first that will get smaller and smaller.\n",
    "\n",
    "The model does not optimize for accuracy, it optimizes for loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0448, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0085, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        #data is a batch of featuresets and labels\n",
    "        X, y = data\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1, 28*28))\n",
    "        loss = F.nll_loss(output, y) #1 of two major ways to calculate loss\n",
    "        loss.backward() #nice feature for pytorch.\n",
    "        optimizer.step()\n",
    "    print(loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.978\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1, 784))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "print(\"Accuracy: \", round(correct/total, 3))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very easy for a small mistake or oversight to cause bias in the NN model. Be careful. Accuracy this high should be a major red flag for real world applications. This is very difficult to obtain in real world projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAANh0lEQVR4nO3df6zV9X3H8deL2ytWtClgwTtKp2PYlLmJ5o7asHWuroyaOmyyMkmmLHOjyWTRxGVzbkvttrSsqRqzmS44aSmxuibWSTLSQmgps3Xq1TJEYMAMthQKOpKKWH7e9/64h+6K93zu5Zzv+QHv5yM5Oed83+d7v+98uS++33M+33M/jggBOPeN63QDANqDsANJEHYgCcIOJEHYgSTe0c6Nnefxcb4mtHOTQCpHdFjH4qhHqjUVdtvzJT0gqUfSv0TEstLrz9cEfdDXNbNJAAXPxPq6tYZP4233SHpQ0sckzZK0yPasRn8egNZq5j37HEm7IuLliDgm6TFJC6ppC0DVmgn7NEk/HPZ8T23ZW9heYnvA9sBxHW1icwCa0UzYR/oQ4G3X3kbE8ojoj4j+Xo1vYnMAmtFM2PdImj7s+Xsl7W2uHQCt0kzYn5M00/Zlts+TdJOk1dW0BaBqDQ+9RcQJ20slfVNDQ28rIuKlyjoDUKmmxtkjYo2kNRX1AqCFuFwWSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJJqaxRXopKlPv6tY/9L7NtSt3fDRm4rrnty6o5GWulpTYbe9W9IhSSclnYiI/iqaAlC9Ko7svxkRr1XwcwC0EO/ZgSSaDXtIWmv7edtLRnqB7SW2B2wPHNfRJjcHoFHNnsbPjYi9tqdIWmd7e0RsHP6CiFguabkkvcuTosntAWhQU0f2iNhbuz8g6QlJc6poCkD1Gg677Qm2Lzr1WNI8SVuqagxAtZo5jZ8q6Qnbp37OVyPiG5V0ha5x+Hc/WKxP+tNXyut/Zlrd2ju+9Xxx3Z5Zlxfrn522olgf1Dvr1l6bM7m47sStxfJZqeGwR8TLkq6ssBcALcTQG5AEYQeSIOxAEoQdSIKwA0nwFdfket7/i8X6Xy5bWazPe+fhYn3u+5bWrU0srin9+DfKw2NTe+oPreHtOLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMsye38w/fU6w/e3hGsf7g7/xSsT5x+7Nn3NMpUwbeaHjd0Ux+7PvF+mDLttw5HNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2ZP7/fnfKdZXbvhwsT5z639W2c5b7Fp4YbE+Ti7WVx26pG5t8MiRhno6m3FkB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkGGc/x/VMnlSs3/Lu1cX6s/eX/678iTPu6P/5V3+5WF+z8AvF+r6TUaz/68KPFKrbi+uei0Y9stteYfuA7S3Dlk2yvc72ztr9aH/vH0CHjeU0/suS5p+27C5J6yNipqT1tecAutioYY+IjZIOnrZ4gaRT8wKtlHRjxX0BqFijH9BNjYh9klS7n1LvhbaX2B6wPXBcRxvcHIBmtfzT+IhYHhH9EdHfq/Gt3hyAOhoN+37bfZJUuz9QXUsAWqHRsK+WtLj2eLGkJ6tpB0CrjDrObvtRSddKutj2HkmflrRM0tds3yrpB5I+2com0bjXbnh/sd5T/kq4ore5SzF8Vf2/K3/Tqm8W173A5XH0W/7ojmK9d/NAsZ7NqP+SEbGoTum6insB0EJcLgskQdiBJAg7kARhB5Ig7EASfMU1uSNRHnvzG28W6/GhK4v133roqbq1my/6cXHdqz//58X6JWu/V6zjrTiyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjLMnd3nvhGJ962enFevf+sgDxfq7x9U/nlx1758V1+17gHH0KnFkB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkGGdP7mQMFus75i0v1vefLP/8+XffWbfWt4px9HbiyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDOfo579ZpRBsJHsfan5e+7f+bvlhbrE1c93dT2UZ1Rj+y2V9g+YHvLsGX32P6R7U212/WtbRNAs8ZyGv9lSfNHWH5/RMyu3dZU2xaAqo0a9ojYKOlgG3oB0ELNfEC31Pbm2mn+xHovsr3E9oDtgeM62sTmADSj0bB/UdIMSbMl7ZN0b70XRsTyiOiPiP5ejW9wcwCa1VDYI2J/RJyMiEFJD0maU21bAKrWUNht9w17+glJW+q9FkB3GHWc3fajkq6VdLHtPZI+Lela27MlhaTdkj7Vwh4xil33XVO3tv2Gfxxl7Z5idem6W4r1y1cyjn62GDXsEbFohMUPt6AXAC3E5bJAEoQdSIKwA0kQdiAJwg4kwVdcu8G48vDXwcXla5Z2/N6DdWurDpWnXF4wYXexjnMHR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9i5wbN7Vxfr3/v6fivV//smldWv/fmN5jP4bX7qiWMe5gyM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOHsXuPYfvlus7z/502L90b+pP4nuhB3PFNcdjMnFOs4dHNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2bvAX19cnt5+8SsfL9YnPF4eSy858OZFDa+Ls8uoR3bb021/2/Y22y/Zvr22fJLtdbZ31u4ntr5dAI0ay2n8CUl3RsQHJF0j6TbbsyTdJWl9RMyUtL72HECXGjXsEbEvIl6oPT4kaZukaZIWSFpZe9lKSTe2qkkAzTujD+hsXyrpKknPSJoaEfukof8QJE2ps84S2wO2B47raHPdAmjYmMNu+0JJj0u6IyJeH+t6EbE8Ivojor9X4xvpEUAFxhR2270aCvojEfH12uL9tvtq9T5JB1rTIoAqjDr0ZtuSHpa0LSLuG1ZaLWmxpGW1+ydb0uE54Nhv9xfrPd5UrG9f8YFifbKerlsbd8EFxXU3XPFvxfqs7/xJsY6zx1jG2edKulnSi/bPfivv1lDIv2b7Vkk/kPTJ1rQIoAqjhj0inpLkOuXrqm0HQKtwuSyQBGEHkiDsQBKEHUiCsANJ8BXXNjjc11usn4zBYv31GeWfX/pj0P+78Mrium8ObijWf+67R8obx1mDIzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4extM3vSTptaf/es7ivVXbvlQ3Vr/bd8vrnvbnvIXF3s2vFCs4+zBkR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcvQ0GN20t1v/jSPmf4ZHL1pY38Ln69Y1Hziuu+re331qsn69ny9vGWYMjO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kMZb52adL+oqkSyQNSloeEQ/YvkfSH0t6tfbSuyNiTasaPZd9bsavdGzbjKPnMZaLak5IujMiXrB9kaTnba+r1e6PiC+0rj0AVRnL/Oz7JO2rPT5ke5ukaa1uDEC1zug9u+1LJV0l6ZnaoqW2N9teYXtinXWW2B6wPXBcR5tqFkDjxhx22xdKelzSHRHxuqQvSpohabaGjvz3jrReRCyPiP6I6O/V+ApaBtCIMYXddq+Ggv5IRHxdkiJif0ScjIhBSQ9JmtO6NgE0a9Sw27akhyVti4j7hi3vG/ayT0jaUn17AKoylk/j50q6WdKLtjfVlt0taZHt2ZJC0m5Jn2pJhwAqMZZP45+S5BFKjKkDZxGuoAOSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiThiGjfxuxXJb0ybNHFkl5rWwNnplt769a+JHprVJW9/XxEvGekQlvD/raN2wMR0d+xBgq6tbdu7Uuit0a1qzdO44EkCDuQRKfDvrzD2y/p1t66tS+J3hrVlt46+p4dQPt0+sgOoE0IO5BER8Jue77t/7a9y/ZdneihHtu7bb9oe5PtgQ73ssL2Adtbhi2bZHud7Z21+xHn2OtQb/fY/lFt322yfX2Heptu+9u2t9l+yfbtteUd3XeFvtqy39r+nt12j6Qdkj4qaY+k5yQtioitbW2kDtu7JfVHRMcvwLD9YUlvSPpKRFxRW/Z5SQcjYlntP8qJEfEXXdLbPZLe6PQ03rXZivqGTzMu6UZJf6AO7rtCXwvVhv3WiSP7HEm7IuLliDgm6TFJCzrQR9eLiI2SDp62eIGklbXHKzX0y9J2dXrrChGxLyJeqD0+JOnUNOMd3XeFvtqiE2GfJumHw57vUXfN9x6S1tp+3vaSTjczgqkRsU8a+uWRNKXD/Zxu1Gm82+m0aca7Zt81Mv15szoR9pGmkuqm8b+5EXG1pI9Juq12uoqxGdM03u0ywjTjXaHR6c+b1Ymw75E0fdjz90ra24E+RhQRe2v3ByQ9oe6binr/qRl0a/cHOtzPz3TTNN4jTTOuLth3nZz+vBNhf07STNuX2T5P0k2SVnegj7exPaH2wYlsT5A0T903FfVqSYtrjxdLerKDvbxFt0zjXW+acXV433V8+vOIaPtN0vUa+kT+fyT9VSd6qNPXL0j6r9rtpU73JulRDZ3WHdfQGdGtkiZLWi9pZ+1+Uhf1tkrSi5I2ayhYfR3q7dc09NZws6RNtdv1nd53hb7ast+4XBZIgivogCQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJ/wPoGO7oWxpf4AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X[0].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[0].view(-1, 784))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[1].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[1].view(-1, 784))[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude this example of neural networks, it is important to note that a lot of things were already done for us. The data was provided and balance issues were already taken care of. Normalization issues were already addressed. Images were all already greyscaled and scaled between 0 and 1 for every pixel value. The next example will use a premade data set of raw images and build a convolutional NN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
